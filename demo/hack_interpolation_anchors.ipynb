{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/monolith/Documents/git/mmseg4med/demo', '/Users/monolith/miniconda3/lib/python38.zip', '/Users/monolith/miniconda3/lib/python3.8', '/Users/monolith/miniconda3/lib/python3.8/lib-dynload', '', '/Users/monolith/.local/lib/python3.8/site-packages', '/Users/monolith/miniconda3/lib/python3.8/site-packages', '/Users/monolith/Documents/git/mmaction2', '/Users/monolith/Documents/git/nnDetection', '/Users/monolith/.local/lib/python3.8/site-packages/IPython/extensions', '/Users/monolith/.ipython', '/Users/monolith/Documents/git/mmseg4med']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "print_tensor = lambda n, x: print(n, type(x), x.shape, x.min(), x.max())\n",
    "print(sys.path)\n",
    "# from pathlib import Pathth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RibFrac101\n",
    "import torch\n",
    "import numpy as np\n",
    "from skimage.transform import resize as skiresize\n",
    "from pathlib import Path\n",
    "from mmseg.datasets.pipelines.io4med import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NIBABEL\n",
      "\n",
      "\n",
      "[IO4Nii] affine raw\n",
      " [[  -0.740234    0.          0.        190.344   ]\n",
      " [   0.         -0.740234    0.        189.5     ]\n",
      " [   0.          0.          1.25     -429.78    ]\n",
      " [   0.          0.          0.          1.      ]]\n",
      "[IO4Nii] affine xyz\n",
      " [[  -0.740234    0.          0.        190.344   ]\n",
      " [   0.         -0.740234    0.        189.5     ]\n",
      " [   0.          0.          1.25     -429.78    ]\n",
      " [   0.          0.          0.          1.      ]]\n",
      "[IO4Nii] xyz dim index [0, 1, 2]\n",
      "[IO4Nii] xyz sign [1, 1, 1]\n",
      "[IO4Nii] image raw <class 'numpy.ndarray'> float64 (512, 512, 349) -3024.0 3071.0\n",
      "[IO4Nii] image xyz <class 'numpy.ndarray'> float64 (512, 512, 349) -3024.0 3071.0\n"
     ]
    }
   ],
   "source": [
    "data_rt = Path('/Users/monolith/Desktop/ribfracture/processed/organize_raw/pub_ribfrac20')\n",
    "caseid = 'RibFrac332'\n",
    "image_fn = f'{caseid}/{caseid}_image.nii.gz'\n",
    "image_raw, af = IO4Nii.read(data_rt/image_fn, verbose = True, dtype = np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacing origin target [0.740234 0.740234 1.25    ] [0.7  0.7  1.25]\n",
      "shape origin target [512 512 349] [541, 541, 349]\n",
      "resize by ski <class 'numpy.ndarray'> int16 (541, 541, 349) -3024 3071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/monolith/Desktop/ribfracture/processed/organize_raw/pub_ribfrac20/RibFrac332/RibFrac332_image_skiresize_3.nii.gz.nii.gz'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_raw = np.array(image_raw.shape)\n",
    "origin_spacing = np.array([abs(af[i, i]) for i in range(3)])\n",
    "\n",
    "target_spacing = np.array([0.7, 0.7, 1.25])\n",
    "shape_new = [round(a) for a in np.array(shape_raw * origin_spacing / target_spacing)]\n",
    "print('spacing origin target', origin_spacing, target_spacing)\n",
    "print('shape origin target', shape_raw, shape_new)\n",
    "order = 3\n",
    "# 0: Nearest-neighbor\n",
    "# 1: Bi-linear (default)\n",
    "# 2: Bi-quadratic\n",
    "# 3: Bi-cubic\n",
    "# 4: Bi-quartic\n",
    "# 5: Bi-quintic\n",
    "\n",
    "image_ski = skiresize(image_raw.astype(float), shape_new, order = order).astype(np.int16)\n",
    "\n",
    "print_tensor('resize by ski', image_ski)\n",
    "IO4Nii.write(image_ski, data_rt, image_fn.replace('image', f'image_skiresize_{order}'), affine_matrix= af)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resize by torch <class 'numpy.ndarray'> int16 (541, 541, 349) -3024 3071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/monolith/Desktop/ribfracture/processed/organize_raw/pub_ribfrac20/RibFrac332/RibFrac332_image_torchresize.nii.gz.nii.gz'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import interpolate as torch_interpolate\n",
    "image_raw_tensor = torch.from_numpy(image_raw).float()[None, None]\n",
    "# size=size, mode=mode, align_corners=align_corners\n",
    "image_torch = torch_interpolate(image_raw_tensor, size = shape_new, mode = 'trilinear', align_corners = None)\n",
    "image_torch = image_torch.cpu().short().numpy()[0, 0]\n",
    "print_tensor('resize by torch', image_torch)\n",
    "IO4Nii.write(image_torch, data_rt, image_fn.replace('image', 'image_torchresize'), affine_matrix= af)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 7, 6)\n",
      "(4, 7, 9)\n",
      "(4, 7, 13)\n",
      "(4, 11, 6)\n",
      "(4, 11, 9)\n",
      "(4, 11, 13)\n",
      "(4, 16, 6)\n",
      "(4, 16, 9)\n",
      "(4, 16, 13)\n",
      "(6, 7, 6)\n",
      "(6, 7, 9)\n",
      "(6, 7, 13)\n",
      "(6, 11, 6)\n",
      "(6, 11, 9)\n",
      "(6, 11, 13)\n",
      "(6, 16, 6)\n",
      "(6, 16, 9)\n",
      "(6, 16, 13)\n",
      "(8, 7, 6)\n",
      "(8, 7, 9)\n",
      "(8, 7, 13)\n",
      "(8, 11, 6)\n",
      "(8, 11, 9)\n",
      "(8, 11, 13)\n",
      "(8, 16, 6)\n",
      "(8, 16, 9)\n",
      "(8, 16, 13)\n",
      "tensor([[2.0000, 3.5000, 3.0000],\n",
      "        [2.0000, 3.5000, 4.5000],\n",
      "        [2.0000, 3.5000, 6.5000],\n",
      "        [2.0000, 5.5000, 3.0000],\n",
      "        [2.0000, 5.5000, 4.5000],\n",
      "        [2.0000, 5.5000, 6.5000],\n",
      "        [2.0000, 8.0000, 3.0000],\n",
      "        [2.0000, 8.0000, 4.5000],\n",
      "        [2.0000, 8.0000, 6.5000],\n",
      "        [3.0000, 3.5000, 3.0000],\n",
      "        [3.0000, 3.5000, 4.5000],\n",
      "        [3.0000, 3.5000, 6.5000],\n",
      "        [3.0000, 5.5000, 3.0000],\n",
      "        [3.0000, 5.5000, 4.5000],\n",
      "        [3.0000, 5.5000, 6.5000],\n",
      "        [3.0000, 8.0000, 3.0000],\n",
      "        [3.0000, 8.0000, 4.5000],\n",
      "        [3.0000, 8.0000, 6.5000],\n",
      "        [4.0000, 3.5000, 3.0000],\n",
      "        [4.0000, 3.5000, 4.5000],\n",
      "        [4.0000, 3.5000, 6.5000],\n",
      "        [4.0000, 5.5000, 3.0000],\n",
      "        [4.0000, 5.5000, 4.5000],\n",
      "        [4.0000, 5.5000, 6.5000],\n",
      "        [4.0000, 8.0000, 3.0000],\n",
      "        [4.0000, 8.0000, 4.5000],\n",
      "        [4.0000, 8.0000, 6.5000]])\n",
      "tensor([[-2.0000, -3.5000,  2.0000,  3.5000, -3.0000,  3.0000],\n",
      "        [-2.0000, -3.5000,  2.0000,  3.5000, -4.5000,  4.5000],\n",
      "        [-2.0000, -3.5000,  2.0000,  3.5000, -6.5000,  6.5000],\n",
      "        [-2.0000, -5.5000,  2.0000,  5.5000, -3.0000,  3.0000],\n",
      "        [-2.0000, -5.5000,  2.0000,  5.5000, -4.5000,  4.5000],\n",
      "        [-2.0000, -5.5000,  2.0000,  5.5000, -6.5000,  6.5000],\n",
      "        [-2.0000, -8.0000,  2.0000,  8.0000, -3.0000,  3.0000],\n",
      "        [-2.0000, -8.0000,  2.0000,  8.0000, -4.5000,  4.5000],\n",
      "        [-2.0000, -8.0000,  2.0000,  8.0000, -6.5000,  6.5000],\n",
      "        [-3.0000, -3.5000,  3.0000,  3.5000, -3.0000,  3.0000],\n",
      "        [-3.0000, -3.5000,  3.0000,  3.5000, -4.5000,  4.5000],\n",
      "        [-3.0000, -3.5000,  3.0000,  3.5000, -6.5000,  6.5000],\n",
      "        [-3.0000, -5.5000,  3.0000,  5.5000, -3.0000,  3.0000],\n",
      "        [-3.0000, -5.5000,  3.0000,  5.5000, -4.5000,  4.5000],\n",
      "        [-3.0000, -5.5000,  3.0000,  5.5000, -6.5000,  6.5000],\n",
      "        [-3.0000, -8.0000,  3.0000,  8.0000, -3.0000,  3.0000],\n",
      "        [-3.0000, -8.0000,  3.0000,  8.0000, -4.5000,  4.5000],\n",
      "        [-3.0000, -8.0000,  3.0000,  8.0000, -6.5000,  6.5000],\n",
      "        [-4.0000, -3.5000,  4.0000,  3.5000, -3.0000,  3.0000],\n",
      "        [-4.0000, -3.5000,  4.0000,  3.5000, -4.5000,  4.5000],\n",
      "        [-4.0000, -3.5000,  4.0000,  3.5000, -6.5000,  6.5000],\n",
      "        [-4.0000, -5.5000,  4.0000,  5.5000, -3.0000,  3.0000],\n",
      "        [-4.0000, -5.5000,  4.0000,  5.5000, -4.5000,  4.5000],\n",
      "        [-4.0000, -5.5000,  4.0000,  5.5000, -6.5000,  6.5000],\n",
      "        [-4.0000, -8.0000,  4.0000,  8.0000, -3.0000,  3.0000],\n",
      "        [-4.0000, -8.0000,  4.0000,  8.0000, -4.5000,  4.5000],\n",
      "        [-4.0000, -8.0000,  4.0000,  8.0000, -6.5000,  6.5000]])\n"
     ]
    }
   ],
   "source": [
    "# Args:\n",
    "#     width: sizes along width dimension (4.0, 6.0, 8.0)\n",
    "#     height: sizes along height dimension (7.0, 11.0, 16.0)\n",
    "#     depth: sizes along depth dimension (6.0, 9.0, 13.0)\n",
    "width = (4, 6, 8)\n",
    "height = (7, 11, 16)\n",
    "depth = (6, 9, 13)\n",
    "from itertools import product\n",
    "def generate_anchors(width, #: Tuple[int],\n",
    "                     height,  #: Tuple[int],\n",
    "                     depth, #: Tuple[int],\n",
    "                     dtype = torch.float, #: Union[torch.device, str]\n",
    "                     device = \"cpu\"): #-> torch.Tensor\n",
    "    \"\"\"\n",
    "    Generate anchors for given width, height and depth sizes\n",
    "\n",
    "    Args:\n",
    "        width: sizes along width dimension (4.0, 6.0, 8.0)\n",
    "        height: sizes along height dimension (7.0, 11.0, 16.0)\n",
    "        depth: sizes along depth dimension (6.0, 9.0, 13.0)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: anchors of shape [n(width) * n(height) * n(depth) , dim * 2]\n",
    "    \"\"\"\n",
    "    aa = product(width, height, depth)\n",
    "    _ = [print(a) for a in aa]\n",
    "    \n",
    "    all_sizes = torch.tensor(list(product(width, height, depth)),\n",
    "                             dtype=dtype, device=device) / 2\n",
    "    print(all_sizes)\n",
    "    anchors = torch.stack(\n",
    "        [-all_sizes[:, 0], -all_sizes[:, 1], all_sizes[:, 0], all_sizes[:, 1],\n",
    "         -all_sizes[:, 2], all_sizes[:, 2]], dim=1\n",
    "        )\n",
    "    print(anchors)\n",
    "    return anchors\n",
    "\n",
    "anchors = generate_anchors(width, height, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'width': [(4.0, 6.0, 8.0), (8.0, 12.0, 16.0), (16.0, 24.0, 32.0), (16.0, 24.0, 32.0)], \n",
    "# 'height': [(7.0, 11.0, 16.0), (14.0, 22.0, 32.0), (28.0, 44.0, 64.0), (56.0, 88.0, 128.0)], \n",
    "# 'depth': [(6.0, 9.0, 13.0), (12.0, 18.0, 26.0), (24.0, 36.0, 52.0), (48.0, 72.0, 104.0)], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "octave scale [1.         1.41421356]\n",
      "scale  [2.         2.82842712]\n",
      "ratio 1/4 tensor([0.8409, 1.0000, 1.1892])\n",
      "ratio units tensor([0.7071, 1.0000, 1.4142])\n",
      "hwd 1 area tensor([[0.7071, 1.0000, 1.4142],\n",
      "        [0.7071, 1.4142, 1.0000],\n",
      "        [1.0000, 0.7071, 1.4142],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.4142, 0.7071],\n",
      "        [1.4142, 0.7071, 1.0000],\n",
      "        [1.4142, 1.0000, 0.7071]]) torch.Size([7, 3])\n",
      "h_ratios tensor([0.7071, 0.7071, 1.0000, 1.0000, 1.0000, 1.4142, 1.4142])\n",
      "w_ratios tensor([1.0000, 1.4142, 0.7071, 1.0000, 1.4142, 0.7071, 1.0000])\n",
      "d_ratios tensor([1.4142, 1.0000, 1.4142, 1.0000, 0.7071, 1.0000, 0.7071])\n",
      "hs tensor([ 5.6569,  8.0000,  5.6569,  8.0000,  8.0000, 11.3137,  8.0000, 11.3137,\n",
      "         8.0000, 11.3137, 11.3137, 16.0000, 11.3137, 16.0000],\n",
      "       dtype=torch.float64)\n",
      "ws tensor([ 8.0000, 11.3137, 11.3137, 16.0000,  5.6569,  8.0000,  8.0000, 11.3137,\n",
      "        11.3137, 16.0000,  5.6569,  8.0000,  8.0000, 11.3137],\n",
      "       dtype=torch.float64)\n",
      "ds tensor([11.3137, 16.0000,  8.0000, 11.3137, 11.3137, 16.0000,  8.0000, 11.3137,\n",
      "         5.6569,  8.0000,  8.0000, 11.3137,  5.6569,  8.0000],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-4.0000, -2.8284, -5.6569,  4.0000,  2.8284,  5.6569],\n",
      "        [-5.6569, -4.0000, -8.0000,  5.6569,  4.0000,  8.0000],\n",
      "        [-5.6569, -2.8284, -4.0000,  5.6569,  2.8284,  4.0000],\n",
      "        [-8.0000, -4.0000, -5.6569,  8.0000,  4.0000,  5.6569],\n",
      "        [-2.8284, -4.0000, -5.6569,  2.8284,  4.0000,  5.6569],\n",
      "        [-4.0000, -5.6569, -8.0000,  4.0000,  5.6569,  8.0000],\n",
      "        [-4.0000, -4.0000, -4.0000,  4.0000,  4.0000,  4.0000],\n",
      "        [-5.6569, -5.6569, -5.6569,  5.6569,  5.6569,  5.6569],\n",
      "        [-5.6569, -4.0000, -2.8284,  5.6569,  4.0000,  2.8284],\n",
      "        [-8.0000, -5.6569, -4.0000,  8.0000,  5.6569,  4.0000],\n",
      "        [-2.8284, -5.6569, -4.0000,  2.8284,  5.6569,  4.0000],\n",
      "        [-4.0000, -8.0000, -5.6569,  4.0000,  8.0000,  5.6569],\n",
      "        [-4.0000, -5.6569, -2.8284,  4.0000,  5.6569,  2.8284],\n",
      "        [-5.6569, -8.0000, -4.0000,  5.6569,  8.0000,  4.0000]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([14, 6])\n"
     ]
    }
   ],
   "source": [
    "base_size = 4 #  = stride\n",
    "ratios = torch.tensor([1/2, 1.0, 2])\n",
    "center = 0\n",
    "octave_base_scale = 2\n",
    "scales_per_octave = 2\n",
    "scale_major = True\n",
    "\n",
    "\n",
    "octave_scales = np.array([2**(i / scales_per_octave) for i in range(scales_per_octave)])\n",
    "scales = octave_scales * octave_base_scale\n",
    "print('octave scale', octave_scales)\n",
    "print('scale ', scales)\n",
    "\n",
    "w = h = d = base_size\n",
    "x_center = y_center = z_center = center\n",
    "\n",
    "ratio_unit = torch.pow(ratios, 1/4)\n",
    "ratio_units = torch.unique(torch.cat([ratio_unit, ratio_unit * ratio_unit]))[::2] # \n",
    "hwd_sizes = torch.tensor(list(product(ratio_units, ratio_units, ratio_units)))\n",
    "hwd_prod = torch.prod(hwd_sizes, axis = -1).view(-1, 1)\n",
    "hwd_sizes_nx4 = torch.cat([hwd_sizes, hwd_prod], axis = -1)\n",
    "hwd_mask = torch.abs(hwd_sizes_nx4[:, -1] - 1 ) < 1e-5\n",
    "hwd1sizes = hwd_sizes[hwd_mask]\n",
    "# all_sizes = torch.tensor(list(product(width, height, depth))\n",
    "# 1/u, 1/u, u^2\n",
    "# 1/u, u, 1\n",
    "# 1/u^2, u, u\n",
    "# 1, 1, 1\n",
    "print('ratio 1/4', ratio_unit)\n",
    "print('ratio units', ratio_units)\n",
    "# print('hwd sizes nx4', hwd_sizes_nx4)\n",
    "print('hwd 1 area', hwd1sizes, hwd1sizes.shape)\n",
    "\n",
    "\n",
    "h_ratios = hwd1sizes[:, 0]\n",
    "w_ratios = hwd1sizes[:, 1]\n",
    "d_ratios = hwd1sizes[:, 2]\n",
    "\n",
    "# print(f'ratios {ratios} ratio unit {ratio_unit}')\n",
    "print('h_ratios', h_ratios)\n",
    "print('w_ratios', w_ratios)\n",
    "print('d_ratios', d_ratios)\n",
    "\n",
    "if scale_major:\n",
    "    ws = (w * w_ratios[:, None] * scales[None, :]).view(-1)\n",
    "    hs = (h * h_ratios[:, None] * scales[None, :]).view(-1)\n",
    "    ds = (d * d_ratios[:, None] * scales[None, :]).view(-1)\n",
    "else:\n",
    "    ws = (w * scales[:, None] * w_ratios[None, :]).view(-1)\n",
    "    hs = (h * scales[:, None] * h_ratios[None, :]).view(-1)\n",
    "    ds = (d * scales[:, None] * d_ratios[None, :]).view(-1)\n",
    "\n",
    "print('hs', hs)\n",
    "print('ws', ws)\n",
    "print('ds', ds)\n",
    "# use float anchor and the anchor's center is aligned with the\n",
    "# pixel center\n",
    "base_anchors = [\n",
    "    x_center - 0.5 * ws, y_center - 0.5 * hs, z_center - 0.5 * ds, \n",
    "    x_center + 0.5 * ws, y_center + 0.5 * hs, z_center + 0.5 * ds\n",
    "]\n",
    "base_anchors = torch.stack(base_anchors, dim=-1) # nx6\n",
    "print(base_anchors)\n",
    "print(base_anchors.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.414213562373095 1.189207115002721 0.8408964152537146 0.7071067811865476 0.7071067811865475\n"
     ]
    }
   ],
   "source": [
    "denom = 2**(1/4)\n",
    "\n",
    "print(denom **2 , denom, 1/denom, 1/denom ** 2, 1/ 2**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
